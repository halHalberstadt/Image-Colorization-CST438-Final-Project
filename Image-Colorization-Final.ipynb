{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096ec476",
   "metadata": {},
   "source": [
    "# Image Colorization Final Project\n",
    "Authors: Aret Tinoco, Keshav Gupta, Hal Halberstadt\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/darthgera/colorization\n",
    "\n",
    "---\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd605224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorsys\n",
    "from pathlib import Path\n",
    "from PIL import Image # for resizing images\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Input, Model, callbacks\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770db43",
   "metadata": {},
   "source": [
    "Ease of reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fb6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f979beb",
   "metadata": {},
   "source": [
    "Now to state the directory of the data to retrieve from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09c590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"C:/Users/smhal/Desktop/archive2\") \n",
    "img_shape = (512, 512, 3)\n",
    "\n",
    "folder_paths = ['color', 'bw',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e138d",
   "metadata": {},
   "source": [
    "Generators\n",
    "\n",
    "The first generator gets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen():\n",
    "    '''Generator for test data\n",
    "    converts RBG image to HSL numpy array'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen():\n",
    "    '''Generator for training data\n",
    "    converts image from 3 channel B/W to 1 channel'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f3e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(subset_name, data_dir, is_color=False):\n",
    "    subset_dir = data_dir / subset_name\n",
    "    pics = subset_dir.glob('*.jpg')\n",
    "    num_pics = int(len(list(pics))/15)\n",
    "    print(f\"#imgs {num_pics}, folder '{subset_name}'\")\n",
    "    \n",
    "    X = np.zeros((num_pics, img_shape[0], img_shape[1], img_shape[2]), dtype='float32')\n",
    "    \n",
    "    for i, pic in enumerate(subset_dir.glob('*.jpg')):\n",
    "        if i < num_pics:\n",
    "            img = load_img(pic)\n",
    "            X[i] = img\n",
    "    \n",
    "    return (X / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17dfe5",
   "metadata": {},
   "source": [
    "Next I want to read the data from the files and then just to make sure I am getting the right data from the right files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b77c313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#imgs 1333, folder 'train_col_images'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# X_train = read_folder(train_folder_paths[1], data_dir) # BW imgs\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mread_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_folder_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [9], line 16\u001b[0m, in \u001b[0;36mread_folder\u001b[1;34m(subset_name, data_dir, is_color)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img)):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img[y])):\n\u001b[1;32m---> 16\u001b[0m             img[y][x] \u001b[38;5;241m=\u001b[39m colorsys\u001b[38;5;241m.\u001b[39mrgb_to_hsv(img[y][x][\u001b[38;5;241m0\u001b[39m],img[y][x][\u001b[38;5;241m1\u001b[39m],img[y][x][\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     17\u001b[0m     X[i] \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bw_data = read_folder(folder_paths[1], data_dir) # BW imgs\n",
    "\n",
    "color_data = read_folder(folder_paths[0], data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()  # delete old models\n",
    "act_fun='relu'\n",
    "\n",
    "inputs=Input(img_shape)\n",
    "\n",
    "# YOUR CONVOLUTIONAL LAYERS GO HERE\n",
    "filters=3\n",
    "\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(inputs)\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(inputs)\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(inputs)\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(inputs)\n",
    "# x = layers.MaxPooling2D(2, padding='same', strides=1)(x)\n",
    "\n",
    "# Flatten and output Block\n",
    "embedding_model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b487c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1faf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input0 = Input(img_shape, name='input0')\n",
    "# input1 = Input(img_shape, name='input1')\n",
    "# input2 = Input(img_shape, name='input2')\n",
    "\n",
    "# sub0 = embedding_model(input0)\n",
    "# sub1 = embedding_model(input1)\n",
    "# sub2 = embedding_model(input2)\n",
    "\n",
    "# pred = layers.Concatenate(axis=1)([sub0, sub1, sub2])\n",
    "\n",
    "# model = Model([input0, input1, input2], pred)\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='mse',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea32ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_input = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "embedding_model.compile(optimizer='rmsprop', loss='mse',  metrics=['loss'])\n",
    "embedding_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75476bbd",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "22e93f1d8be2154c5a04e6b058ce42b63f28e5f9eb04901314d0231bac8a129e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
