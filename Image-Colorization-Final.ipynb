{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096ec476",
   "metadata": {},
   "source": [
    "# Image Colorization Final Project\n",
    "Authors: Aret Tinoco, Keshav Gupta, Hal Halberstadt\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/darthgera/colorization\n",
    "\n",
    "---\n",
    "\n",
    "## Imports\n",
    "\n",
    "We have to import some unsual libraries in order to get the RGB values of our target images into HSL format, and a few more for ease of viewing and on the same note ease displaying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd605224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorsys\n",
    "from pathlib import Path\n",
    "from PIL import Image # for resizing images\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Input, Model, callbacks, utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770db43",
   "metadata": {},
   "source": [
    "Ease of reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fb6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f979beb",
   "metadata": {},
   "source": [
    "Now to state the directory of the data to retrieve from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09c590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"C:/Users/smhal/Desktop/archive2\") \n",
    "img_shape = (512, 512, 3)\n",
    "\n",
    "folder_paths = ['color', 'bw', 'color_val', 'bw_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5642bf1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Useful Functions\n",
    "\n",
    "We need a function to make conversion of each image easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f01b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_conv(image, width=512, height=512):\n",
    "    image_ = np.array(image, dtype='float32')\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pixel = image_[x][y]\n",
    "            image_[x][y] = colorsys.rgb_to_hls(pixel[0], pixel[1], pixel[2])\n",
    "    return image_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5abfea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Generator\n",
    "\n",
    "Since we cannot hope to hold onto 18000 images in our kernel, we have to use a generator in order to be able to get data from the file and then train on that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b1475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(utils.Sequence): \n",
    "    '''\n",
    "    adapted from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    \n",
    "    Generates a color and black & white image for training data\n",
    "    '''\n",
    "    def __init__(self, list_IDs_color, list_IDs_bw, batch_size=8, \n",
    "                 dim=img_shape, n_channels=3, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs_bw\n",
    "        self.list_IDs = list_IDs_color\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp_bw = [self.list_IDs[k] for k in indexes]\n",
    "        list_IDs_temp_color = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp_bw, list_IDs_temp_color)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp_bw, list_IDs_temp_color):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp_bw):\n",
    "            # B/W image\n",
    "            X[i] = load_img(ID)\n",
    "            X[i] = np.array(X[i], dtype='float32')\n",
    "\n",
    "            # target image\n",
    "            y[i] = load_img(list_IDs_temp_color[i])\n",
    "            y[i] = np.array(hls_conv(y[i]), dtype='float32')\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09af90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': img_shape,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "bw_dir_train = data_dir / folder_paths[1]\n",
    "color_dir_train = data_dir / folder_paths[0]\n",
    "\n",
    "partition_bw = list(bw_dir_train.glob('*.jpg'))\n",
    "partition_color = list(bw_dir_train.glob('*.jpg'))\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition_bw, partition_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6198fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': img_shape,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "bw_dir_val = data_dir / folder_paths[3]\n",
    "color_dir_val = data_dir / folder_paths[2]\n",
    "\n",
    "partition_bw = list(bw_dir_val.glob('*.jpg'))\n",
    "partition_color = list(color_dir_val.glob('*.jpg'))\n",
    "\n",
    "\n",
    "validation_generator = DataGenerator(partition_bw, partition_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17dfe5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model(s)\n",
    "\n",
    "Next I want to read the data from the files and then just to make sure I am getting the right data from the right files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5e6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()  # delete old models\n",
    "act_fun='relu'\n",
    "\n",
    "inputs=Input(img_shape)\n",
    "\n",
    "# YOUR CONVOLUTIONAL LAYERS GO HERE\n",
    "filters=3\n",
    "\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(inputs)\n",
    "x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(x)\n",
    "# x = layers.MaxPooling2D(2, padding='same', strides=1)(x)\n",
    "\n",
    "# x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(x)\n",
    "# x = layers.SeparableConv2D(filters, 2, padding='same', activation=act_fun)(x)\n",
    "\n",
    "output = x\n",
    "# Flatten and output Block\n",
    "embedding_model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b487c01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 512, 512, 3)       24        \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 512, 512, 3)       24        \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1faf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input0 = Input(img_shape, name='input0')\n",
    "# input1 = Input(img_shape, name='input1')\n",
    "# input2 = Input(img_shape, name='input2')\n",
    "\n",
    "# sub0 = embedding_model(input0)\n",
    "# sub1 = embedding_model(input1)\n",
    "# sub2 = embedding_model(input2)\n",
    "\n",
    "# pred = layers.Concatenate(axis=1)([sub0, sub1, sub2])\n",
    "\n",
    "# model = Model([input0, input1, input2], pred)\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='mse',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9cc95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac0c44",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea32ab2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_model.compile(optimizer='rmsprop', loss='mse',  metrics=['accuracy'])\n",
    "embedding_model.fit(training_generator, \n",
    "                    epochs=5,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=32)\n",
    "# embedding_model.fit(training_generator, \n",
    "#                     epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75476bbd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "Para1..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "22e93f1d8be2154c5a04e6b058ce42b63f28e5f9eb04901314d0231bac8a129e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
