{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096ec476",
   "metadata": {},
   "source": [
    "# Image Colorization Final Project\n",
    "Authors: Aret Tinoco, Keshav Gupta, Hal Halberstadt\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/darthgera/colorization\n",
    "\n",
    "---\n",
    "\n",
    "## Imports\n",
    "\n",
    "We have to import some unsual libraries in order to get the RGB values of our target images into HSL format, and a few more for ease of viewing and on the same note ease displaying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd605224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import colorsys\n",
    "from pathlib import Path\n",
    "from PIL import Image # for resizing images\n",
    "\n",
    "from skimage import io, color\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Input, Model, callbacks, utils, callbacks, optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770db43",
   "metadata": {},
   "source": [
    "Ease of reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fb6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f979beb",
   "metadata": {},
   "source": [
    "Now to state the directory of the data to retrieve from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09c590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"C:/Users/smhal/Desktop/archive\") \n",
    "img_shape = (512, 512, 3)\n",
    "# shrink_shape = img_shape\n",
    "shrink_shape = (256, 256, 3)\n",
    "# shrink_shape = (128, 128, 3)\n",
    "img_taken = 100\n",
    "\n",
    "folder_paths = ['color', 'bw', 'color_val', 'bw_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5642bf1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Useful Functions\n",
    "\n",
    "We need a function to make conversion of each image easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5abfea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Generator\n",
    "\n",
    "Since we cannot hope to hold onto 18000 images in our kernel, we have to use a generator in order to be able to get data from the file and then train on that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b1475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(utils.Sequence): \n",
    "    '''\n",
    "    adapted from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    \n",
    "    Generates a color (rbg/hls) and black & white image for training data\n",
    "    '''\n",
    "    def __init__(self, ids, batch_size=1, \n",
    "                 dim=shrink_shape, n_channels=3, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = ids\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # B/W image\n",
    "            img = load_img(ID)\n",
    "            img = img.resize(shrink_shape[:2])\n",
    "            img = np.array(img, dtype=np.float32)/255\n",
    "            img = img ** 1/2.2 #rgb to srgb\n",
    "            img = color.rgb2lab(img)\n",
    "            \n",
    "            X[i] = img\n",
    "            \n",
    "            # get location of color image\n",
    "            color_ID = str(ID)\n",
    "            color_ID = color_ID.replace(\"bw\", \"color\")\n",
    "            \n",
    "            # target image\n",
    "            img_y = load_img(color_ID)\n",
    "            img_y = img_y.resize(shrink_shape[:2])\n",
    "            img_y = np.array(img_y, dtype=np.float32)/255\n",
    "            img_y = img_y ** 1/2.2 #rgb to srgb\n",
    "            img_y = color.rgb2lab(img_y)\n",
    "#             img_y = color.rgb2xyz(img_y)\n",
    "#             img_y = color.xyz2lab(img_y)\n",
    "\n",
    "            y[i] = img_y\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09af90c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset locations\n",
    "bw_dir_train = data_dir / folder_paths[1]\n",
    "# color_dir_train = data_dir / folder_paths[0]\n",
    "#[:img_taken]\n",
    "partition_bw = list(bw_dir_train.glob('*.jpg'))\n",
    "# partition_color = list(color_dir_train.glob('*.jpg'))\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6198fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset locations\n",
    "bw_dir_val = data_dir / folder_paths[3]\n",
    "color_dir_val = data_dir / folder_paths[2]\n",
    "\n",
    "partition_bw = list(bw_dir_val.glob('*.jpg'))\n",
    "partition_color = list(color_dir_val.glob('*.jpg'))\n",
    "\n",
    "# Generators\n",
    "validation_generator = DataGenerator(partition_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17dfe5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model(s)\n",
    "\n",
    "Next I want to read the data from the files and then just to make sure I am getting the right data from the right files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7573a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()  # Just for sanity\n",
    "filter_size = 1\n",
    "_padding = 'same'\n",
    "_stride = 2\n",
    "k_size = 3\n",
    "_filters = 16\n",
    "dropout_rate = 0.5\n",
    "act_fun = layers.LeakyReLU(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c1cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = Input(shrink_shape, name=\"img_input\")\n",
    "'''U-shape model'''\n",
    "\n",
    "x = layers.Conv2D(3, k_size, activation=act_fun, padding=_padding)(inputs)\n",
    "residual = x\n",
    "\n",
    "# topmost start\n",
    "x = layers.Conv2D(_filters, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D(_filters, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(_filters, k_size, activation=act_fun, padding=_padding)(x)\n",
    "residual1 = x\n",
    "\n",
    "# 2nd layer start\n",
    "x = layers.Conv2D(_filters*2, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "# x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D(_filters*2, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(_filters*2, k_size, activation=act_fun, padding=_padding)(x)\n",
    "residual2 = x\n",
    "\n",
    "# 3rd layer start\n",
    "x = layers.Conv2D(_filters*3, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "residual3 = x\n",
    "x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D(_filters*3, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(_filters*3, k_size, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "# Bottom of \"U\"/ Lowest layer\n",
    "x = layers.Conv2D(_filters*6, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "# x = layers.Conv2D(_filters*6, k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D(_filters*6, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "# x = layers.Conv2D(_filters*6, k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.Conv2DTranspose(_filters*6, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "# # 3rd layer end\n",
    "x = layers.Conv2D((_filters*3), k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.Add()([residual3, x])\n",
    "x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D((_filters*4), k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose((_filters*3), k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "# # 2nd layer end\n",
    "x = layers.Conv2D(_filters*2, k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.Add()([residual2, x])\n",
    "x = layers.SpatialDropout2D(dropout_rate)(x)\n",
    "x = layers.Conv2D(_filters*2, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(_filters*2, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "# # topmost end\n",
    "x = layers.Conv2D(_filters, k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.Add()([residual1, x])\n",
    "x = layers.Conv2D(_filters, k_size, padding=_padding)(x)\n",
    "x = layers.BatchNormalization(axis=3)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(_filters, k_size, strides=_stride, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "# # outermost part\n",
    "x = layers.Conv2D(3, k_size, activation=act_fun, padding=_padding)(x)\n",
    "x = layers.Add()([residual, x])\n",
    "x = layers.Conv2D(3, k_size, activation=act_fun, padding=_padding)(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cc95ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 3)  84          img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 448         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 16) 2320        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   4640        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   9248        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 48)   13872       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 32, 32, 48)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   20784       spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 48)   20784       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   41568       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 16, 16, 96)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 96)   83040       spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 96)   384         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 96)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 96)   83040       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   41520       conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 48)   0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 32, 32, 48)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   27712       spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 48)   27696       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 32)   13856       conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 32)   0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_4 (SpatialDro (None, 64, 64, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 32)   9248        spatial_dropout2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 9248        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 16) 4624        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 16) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 16) 2320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 16) 64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 128, 128, 16) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 16) 2320        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 3)  435         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256, 256, 3)  0           conv2d[0][0]                     \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 3)  84          add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 431,675\n",
      "Trainable params: 431,067\n",
      "Non-trainable params: 608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0f2c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7423f8d9",
   "metadata": {},
   "source": [
    "Creating a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebd7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_monitor = \"val_loss\"\n",
    "my_callbacks = [\n",
    "    callbacks.EarlyStopping(monitor=my_monitor, patience=6, min_delta=0.2),\n",
    "    callbacks.ReduceLROnPlateau(monitor=my_monitor, factor=0.3, patience=3, min_delta=0.2, verbose=1)\n",
    "]\n",
    "\n",
    "my_opt = optimizers.RMSprop(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea32ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 4222/18000 [======>.......................] - ETA: 7:31 - loss: 4.9822 - accuracy: 0.8458"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=my_opt, loss='mean_absolute_error',  metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_generator, callbacks=my_callbacks, validation_data=validation_generator, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d504b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Results\n",
    "\n",
    "Here is a few images that were colorized with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 5\n",
    "image_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7b6f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs_x = np.zeros((n_img, shrink_shape[0], shrink_shape[1], shrink_shape[2]), dtype='float32')\n",
    "imgs_p = np.zeros((n_img, shrink_shape[0], shrink_shape[1], shrink_shape[2]), dtype='float32')\n",
    "i = 0\n",
    "for location in partition_bw[:n_img]:\n",
    "    img = load_img(location)\n",
    "    img = img.resize(shrink_shape[:2])\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    imgs_x[i] = img/255\n",
    "    imgs_p[i] = img/255\n",
    "    i += 1\n",
    "    \n",
    "plt.imshow(imgs_x[image_number]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23648b81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = model.predict(color.rgb2lab((imgs_p**1/2.2)))\n",
    "# output = model.predict(color.rgb2lab((imgs_p)))\n",
    "# output = model.predict(imgs_p)\n",
    "# for imgs in output:\n",
    "#     print(imgs[0][0])\n",
    "# print(color.lab2rgb(imgs_p[image_number])[0][0])\n",
    "output = color.lab2rgb(output[image_number]*2.2)\n",
    "\n",
    "# output = color.lab2xyz(output[image_number])\n",
    "# output = color.xyz2rgb(output)\n",
    "# print(output[image_number][400:405])\n",
    "# output = output\n",
    "\n",
    "plt.imshow(output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d20df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs_y = np.zeros((n_img, shrink_shape[0], shrink_shape[1], shrink_shape[2]), dtype='float32')\n",
    "i = 0\n",
    "for location in partition_color[:n_img]:\n",
    "    img = load_img(location)\n",
    "    img = img.resize(shrink_shape[:2])\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    imgs_y[i] = img/255\n",
    "    i += 1\n",
    "    \n",
    "plt.imshow(imgs_y[image_number]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75476bbd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "Para1..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "22e93f1d8be2154c5a04e6b058ce42b63f28e5f9eb04901314d0231bac8a129e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
